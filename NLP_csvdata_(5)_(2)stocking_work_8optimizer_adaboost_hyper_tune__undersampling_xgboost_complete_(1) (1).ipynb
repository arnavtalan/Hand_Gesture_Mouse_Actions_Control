{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft6w7MBPa-mS",
        "outputId": "b25ab59e-5f39-42d5-8554-612a29cc3f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.14.0)\n",
            "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow_text)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow_text\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow_text-2.13.0 typing-extensions-4.5.0\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install nlpaug\n",
        "#!pip install tensorflow-addons\n",
        "#!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZLJ9FpjAV6zy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import nlpaug.augmenter.word as naw\n",
        "import re\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "import xgboost as xgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G42kj34fbLsa"
      },
      "outputs": [],
      "source": [
        "ds = pd.read_csv('/content/train_output - train_output(1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0jZ3NzTolqDG"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    return text\n",
        "\n",
        "ds['Text'] = ds['Text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hZEt6GRsbOiP",
        "outputId": "87736274-a258-4a90-ec78-4afb9cd4fcb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Text     Label\n",
              "0            IN THE HIGH COURT OF KARNATAKA,         ...  PREAMBLE\n",
              "1              BEFORE  THE HON'BLE MR.JUSTICE ANAND B...  PREAMBLE\n",
              "2      This Criminal Appeal is filed under Section 37...  PREAMBLE\n",
              "3               This appeal coming on for hearing thi...  PREAMBLE\n",
              "4              Heard the learned Counsel for the appe...      NONE\n",
              "...                                                  ...       ...\n",
              "28981    So Section 132 of the Evidence Act sufficien...     RATIO\n",
              "28982    For the reasons aforesaid, the appeal is all...       RPC\n",
              "28983  The judgment and order dated April 27, 1987 pa...       RPC\n",
              "28984                                             R.S.S.      NONE\n",
              "28985                                    Appeal allowed.       RPC\n",
              "\n",
              "[28986 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9b5649a1-e6a1-48dd-b2cb-8195075e44a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IN THE HIGH COURT OF KARNATAKA,         ...</td>\n",
              "      <td>PREAMBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BEFORE  THE HON'BLE MR.JUSTICE ANAND B...</td>\n",
              "      <td>PREAMBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This Criminal Appeal is filed under Section 37...</td>\n",
              "      <td>PREAMBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This appeal coming on for hearing thi...</td>\n",
              "      <td>PREAMBLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Heard the learned Counsel for the appe...</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28981</th>\n",
              "      <td>So Section 132 of the Evidence Act sufficien...</td>\n",
              "      <td>RATIO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28982</th>\n",
              "      <td>For the reasons aforesaid, the appeal is all...</td>\n",
              "      <td>RPC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28983</th>\n",
              "      <td>The judgment and order dated April 27, 1987 pa...</td>\n",
              "      <td>RPC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28984</th>\n",
              "      <td>R.S.S.</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28985</th>\n",
              "      <td>Appeal allowed.</td>\n",
              "      <td>RPC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28986 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b5649a1-e6a1-48dd-b2cb-8195075e44a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a9579bf6-e7a3-4012-be49-89d87f5c790a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9579bf6-e7a3-4012-be49-89d87f5c790a')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a9579bf6-e7a3-4012-be49-89d87f5c790a button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b5649a1-e6a1-48dd-b2cb-8195075e44a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b5649a1-e6a1-48dd-b2cb-8195075e44a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ds.dropna(axis=0, how='any')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2Sp4XC9bctwn"
      },
      "outputs": [],
      "source": [
        "new_ds=ds.loc[ds['Label'].isin(['FAC','ARG_RESPONDENT', 'ARG_PETITIONER', 'ISSUE'])]\n",
        "#new_ds = ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4CVvqlbcxnG",
        "outputId": "022d0d67-c068-4493-b945-3a1fc834330e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes: ['FAC' 'ARG_RESPONDENT' 'ARG_PETITIONER' 'ISSUE']\n"
          ]
        }
      ],
      "source": [
        "unique_classes = new_ds['Label'].unique()\n",
        "print(\"Unique classes:\", unique_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm6_YFGUUg4k",
        "outputId": "1d7fa551-8937-49c5-9d65-39f3a426127b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-0f393c6c280d>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_ds[[\"Label\"]] = new_ds[[\"Label\"]].apply(LabelEncoder().fit_transform)\n"
          ]
        }
      ],
      "source": [
        "new_ds[[\"Label\"]] = new_ds[[\"Label\"]].apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ar3VJxXNc4rh",
        "outputId": "f07a0d97-c090-412e-8c73-9ca9e86a9e8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'name = \"new_ds.csv\"\\nnew_ds.to_csv(name, index=False)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "new_ds\n",
        "'''name = \"new_ds.csv\"\n",
        "new_ds.to_csv(name, index=False)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OkCPItnoc_qg"
      },
      "outputs": [],
      "source": [
        "X = new_ds['Text']\n",
        "y = new_ds['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "miqvh5ckmZ45"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E_7o2QYtdFVm"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X6GkjEp2bCMr"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train.to_frame(), y_train)\n",
        "X_train_resampled = X_train_resampled.squeeze()\n",
        "y_train_resampled = y_train_resampled.squeeze()\n",
        "\n",
        "X_test_resampled, y_test_resampled = rus.fit_resample(X_test.to_frame(), y_test)\n",
        "X_test_resampled = X_test_resampled.squeeze()\n",
        "y_test_resampled = y_test_resampled.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rLh-CSdZ98ZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_resampled, dtype=tf.string)\n",
        "y_train_tensor = tf.convert_to_tensor(tf.keras.utils.to_categorical(y_train_resampled, num_classes=13), dtype=tf.float32)\n",
        "\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_resampled, dtype=tf.string)\n",
        "y_test_tensor = tf.convert_to_tensor(tf.keras.utils.to_categorical(y_test_resampled, num_classes=13), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n97kwVsbdMfE"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_zR1xrp38Je",
        "outputId": "bf8041c9-981b-4204-a741-9ed05d4ccf31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "outputs['pooled_output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9v_3gschfUAr"
      },
      "outputs": [],
      "source": [
        "X_train_bert_embed = bert_preprocess(X_train_resampled)\n",
        "X_train_bert_embed = bert_encoder(X_train_bert_embed)[\"pooled_output\"]\n",
        "\n",
        "X_test_bert_embed = bert_preprocess(X_test_resampled)\n",
        "X_test_bert_embed = bert_encoder(X_test_bert_embed)[\"pooled_output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g2_WwXTz4HLI"
      },
      "outputs": [],
      "source": [
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "\n",
        "l = tf.keras.layers.Dense(128, activation='gelu', name=\"hidden\")(l)\n",
        "l = tf.keras.layers.Dropout(0.5, name=\"dropout_2\")(l)\n",
        "\n",
        "l = tf.keras.layers.Dense(64, activation='gelu', name=\"hidden_2\")(l)\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout_3\")(l)\n",
        "\n",
        "l = tf.keras.layers.Dense(32, activation='gelu', name=\"hidden_3\")(l)\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout_4\")(l)\n",
        "\n",
        "l = tf.keras.layers.Dense(16, activation='gelu', name=\"hidden_4\")(l)\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout_5\")(l)\n",
        "\n",
        "output_layer = tf.keras.layers.Dense(13, activation='softmax', name=\"output\")(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MciiM7re4Nvr"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[text_input], outputs = [output_layer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5kldC1X4R8L",
        "outputId": "f635a67c-ffa2-4414-9db0-9f2258b04af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)    {'input_type_ids': (None,    0         ['text[0][0]']                \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)  {'default': (None, 768),     1094822   ['keras_layer[0][0]',         \n",
            "                              'sequence_output': (None,   41         'keras_layer[0][1]',         \n",
            "                              128, 768),                             'keras_layer[0][2]']         \n",
            "                              'pooled_output': (None, 7                                           \n",
            "                             68),                                                                 \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 768),                                                         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)]}                                                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 768)                  0         ['keras_layer_1[0][13]']      \n",
            "                                                                                                  \n",
            " hidden (Dense)              (None, 128)                  98432     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['hidden[0][0]']              \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)            (None, 64)                   8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64)                   0         ['hidden_2[0][0]']            \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)            (None, 32)                   2080      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 32)                   0         ['hidden_3[0][0]']            \n",
            "                                                                                                  \n",
            " hidden_4 (Dense)            (None, 16)                   528       ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 16)                   0         ['hidden_4[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 13)                   221       ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109591758 (418.06 MB)\n",
            "Trainable params: 109517 (427.80 KB)\n",
            "Non-trainable params: 109482241 (417.64 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hWbt-sll4Ur_"
      },
      "outputs": [],
      "source": [
        "METRICS = [tf.keras.metrics.F1Score(\n",
        "    average=None, threshold=None, name='f1_score', dtype=None\n",
        "),\n",
        "    tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "optimizer1 = tf.keras.optimizers.Adafactor(\n",
        "    learning_rate=0.001,\n",
        "    beta_2_decay=-0.8,\n",
        "    epsilon_1=1e-30,\n",
        "    epsilon_2=0.001,\n",
        "    clip_threshold=1.0,\n",
        "    relative_step=True,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adafactor')\n",
        "optimizer2=tf.keras.optimizers.AdamW(\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=0.004,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='AdamW')\n",
        "optimizer3 = tf.keras.optimizers.Lion(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.99,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Lion')\n",
        "optimizer4=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adam')\n",
        "\n",
        "optimizer5=tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"SGD\")\n",
        "\n",
        "optimizer6=tf.keras.optimizers.Adadelta(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.95,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"Adadelta\")\n",
        "\n",
        "optimizer7=tf.keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"Adagrad\")\n",
        "\n",
        "optimizer8=tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=100,\n",
        "    jit_compile=True,\n",
        "    name=\"RMSprop\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwhpi04F4v4C",
        "outputId": "260e2810-072d-4960-902e-38d5f0aa8ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 14s 346ms/step\n",
            "33/33 [==============================] - 14s 363ms/step\n",
            "33/33 [==============================] - 12s 340ms/step\n",
            "33/33 [==============================] - 12s 348ms/step\n",
            "33/33 [==============================] - 12s 350ms/step\n",
            "33/33 [==============================] - 12s 333ms/step\n",
            "33/33 [==============================] - 12s 336ms/step\n",
            "33/33 [==============================] - 12s 346ms/step\n"
          ]
        }
      ],
      "source": [
        "base_models = []\n",
        "\n",
        "model_1 = tf.keras.models.clone_model(model)\n",
        "model_1.compile(optimizer=optimizer1, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_1)\n",
        "\n",
        "model_2 = tf.keras.models.clone_model(model)\n",
        "model_2.compile(optimizer=optimizer2, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_2)\n",
        "\n",
        "model_3 = tf.keras.models.clone_model(model)\n",
        "model_3.compile(optimizer=optimizer3, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_3)\n",
        "\n",
        "model_4 = tf.keras.models.clone_model(model)\n",
        "model_4.compile(optimizer=optimizer4, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_4)\n",
        "\n",
        "model_5 = tf.keras.models.clone_model(model)\n",
        "model_5.compile(optimizer=optimizer5, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_5)\n",
        "\n",
        "model_6 = tf.keras.models.clone_model(model)\n",
        "model_6.compile(optimizer=optimizer6, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_6)\n",
        "\n",
        "model_7 = tf.keras.models.clone_model(model)\n",
        "model_7.compile(optimizer=optimizer7, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_7)\n",
        "\n",
        "model_8 = tf.keras.models.clone_model(model)\n",
        "model_8.compile(optimizer=optimizer8, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_8)\n",
        "\n",
        "train_predictions = []\n",
        "for model in base_models:\n",
        "    train_pred = model.predict(X_train_tensor)\n",
        "    train_predictions.append(train_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "casT750TFa1m"
      },
      "outputs": [],
      "source": [
        "stacked_train_predictions = np.hstack(train_predictions)\n",
        "X_train_combined = np.hstack((X_train_bert_embed, stacked_train_predictions))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj5j9ifGhyg1",
        "outputId": "fdd1f3b9-7f38-4e95-da55-b9aa836553af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 4s 323ms/step\n",
            "14/14 [==============================] - 5s 368ms/step\n",
            "14/14 [==============================] - 4s 322ms/step\n",
            "14/14 [==============================] - 4s 328ms/step\n",
            "14/14 [==============================] - 5s 355ms/step\n",
            "14/14 [==============================] - 4s 330ms/step\n",
            "14/14 [==============================] - 5s 339ms/step\n",
            "14/14 [==============================] - 5s 353ms/step\n"
          ]
        }
      ],
      "source": [
        "test_predictions = []\n",
        "for model in base_models:\n",
        "    test_pred = model.predict(X_test_tensor)\n",
        "    test_predictions.append(test_pred)\n",
        "\n",
        "stacked_test_predictions = np.hstack(test_predictions)\n",
        "X_test_combined = np.hstack((X_test_bert_embed, stacked_test_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Gq4RnRC_XGVZ"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7LrrIgwLXH8q"
      },
      "outputs": [],
      "source": [
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aMkDoR0_e5hD"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(xgb_classifier, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "grid_search.fit(X_train_combined, np.array(y_train_resampled))\n",
        "\n",
        "best_n_estimators = grid_search.best_params_['n_estimators']\n",
        "best_learning_rate = grid_search.best_params_['learning_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAhWmpt_XUc0",
        "outputId": "5edd7f53-6849-4ecf-a49f-39af8394a8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best n_estimators: 150\n",
            "Best learning_rate: 0.2\n"
          ]
        }
      ],
      "source": [
        "print(\"Best n_estimators:\", best_n_estimators)\n",
        "print(\"Best learning_rate:\", best_learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bd48DqRbWPPE"
      },
      "outputs": [],
      "source": [
        "xgb_classifier = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=4,\n",
        "    learning_rate=best_learning_rate,\n",
        "    n_estimators=best_n_estimators,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "model = xgb_classifier.fit(X_train_combined, y_train_resampled)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "siofyvC2FieO"
      },
      "outputs": [],
      "source": [
        "predicted_labels = model.predict(X_test_combined)\n",
        "predicted_class_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HvI8fW9ijEk",
        "outputId": "e09712e2-253a-41d0-c51b-289ec950bf8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 1 1 1 2 1 1 0 1 2 1 2 1 0 0 2 0 0 1 1]\n"
          ]
        }
      ],
      "source": [
        "print(predicted_class_labels[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpb044EJGTzJ",
        "outputId": "cfff4f7c-eb02-475f-aa93-43bf01038bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[42 42 19  4]\n",
            " [33 42 24  8]\n",
            " [15 19 66  7]\n",
            " [ 5  6  6 90]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.39      0.42       107\n",
            "           1       0.39      0.39      0.39       107\n",
            "           2       0.57      0.62      0.59       107\n",
            "           3       0.83      0.84      0.83       107\n",
            "\n",
            "    accuracy                           0.56       428\n",
            "   macro avg       0.56      0.56      0.56       428\n",
            "weighted avg       0.56      0.56      0.56       428\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "test_predictions = xgb_classifier.predict(X_test_combined)\n",
        "predicted_class_labels = label_encoder.inverse_transform(test_predictions)\n",
        "true_class_labels = label_encoder.inverse_transform(y_test_resampled)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_class_labels, predicted_class_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(true_class_labels, predicted_class_labels)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "Xk8vN0fsPRWX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiUtwVZgIswD",
        "outputId": "3a9f5fb7-ca74-45e1-ca41-52861a5efa6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5607476635514018\n",
            "Precision: 0.5567568702370206\n",
            "Recall: 0.5607476635514018\n",
            "F1-score: 0.5581646002438082\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(true_class_labels, predicted_class_labels)\n",
        "precision = precision_score(true_class_labels, predicted_class_labels, average='macro')\n",
        "recall = recall_score(true_class_labels, predicted_class_labels, average='macro')\n",
        "f1 = f1_score(true_class_labels, predicted_class_labels, average='macro')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gnH4m4U4zuD"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDmRwUIkM5r_"
      },
      "outputs": [],
      "source": [
        "#model.save(\"NLP_TEXT_CLASSIFICATION_saved_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcuvgMKXeqk8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCVxS_d7WaP6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6n_RFK4dao6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6jdnLxXdcx_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smyUOjFWoPLY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHKPARkhuXnz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk7y0osvy5Wm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wDfiaUyzz6Gx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "257112d4-9fbd-4c01-9228-9e1dab5c1740"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-2f7aa2428f89>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Put your statement here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'3. The court below answered the above points in the affirmative and accordingly had convicted the accused to undergo simple imprisonment for three years and pay a fine of Rs.5,000/- for the offence punishable under section 498-A IPC and 10 years simple imprisonment and to pay fine of Rs.10,000/- for the offence punishable under Section 306 of the IPC.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-2f7aa2428f89>\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mpredicted_class_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   1524\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             class_probs = super().predict(\n\u001b[0m\u001b[1;32m   1526\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m                 \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1115\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 )\n\u001b[1;32m   2268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2270\u001b[0m                     \u001b[0;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m                     \u001b[0;34mf\"got {data.shape[1]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 872, got 1"
          ]
        }
      ],
      "source": [
        "#model = tf.keras.models.load_model(\"LLP_saved_model\")\n",
        "def check(line):\n",
        "  line = np.array(line).reshape(1, -1)\n",
        "  prediction = model.predict(line)\n",
        "  predicted_labels = np.argmax(prediction, axis=1)\n",
        "  predicted_class_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "  dic = {0: 'ANALYSIS', 1: 'ARG_PETITIONER', 2: 'ARG_RESPONDENT', 3: 'FAC', 4: 'ISSUE', 5: 'NONE', 6: 'PREAMBLE', 7: 'PRE_NOT_RELIED', 8: 'PRE_RELIED', 9: 'RATIO', 10: 'RLC', 11: 'RPC', 12: 'STA'}\n",
        "\n",
        "  for label in predicted_class_labels:\n",
        "    if label in dic:\n",
        "      print(dic[label])\n",
        "#Put your statement here:\n",
        "line = ['3. The court below answered the above points in the affirmative and accordingly had convicted the accused to undergo simple imprisonment for three years and pay a fine of Rs.5,000/- for the offence punishable under section 498-A IPC and 10 years simple imprisonment and to pay fine of Rs.10,000/- for the offence punishable under Section 306 of the IPC.']\n",
        "check(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_sUgRLg1nRk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7MXPbYTI204"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}