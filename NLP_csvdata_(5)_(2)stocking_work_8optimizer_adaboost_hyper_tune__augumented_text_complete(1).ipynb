{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft6w7MBPa-mS"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install nlpaug\n",
        "#!pip install tensorflow-addons\n",
        "#!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLJ9FpjAV6zy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import nlpaug.augmenter.word as naw\n",
        "import re\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G42kj34fbLsa"
      },
      "outputs": [],
      "source": [
        "ds = pd.read_csv('/content/train_output - train_output(1).csv')\n",
        "class_distribution = ds['Label'].value_counts()\n",
        "print(class_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jZ3NzTolqDG"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    return text\n",
        "\n",
        "ds['Text'] = ds['Text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZEt6GRsbOiP"
      },
      "outputs": [],
      "source": [
        "ds.dropna(axis=0, how='any')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Sp4XC9bctwn"
      },
      "outputs": [],
      "source": [
        "new_ds=ds.loc[ds['Label'].isin(['FAC','ARG_RESPONDENT', 'ARG_PETITIONER', 'ISSUE'])]\n",
        "#new_ds = ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4CVvqlbcxnG"
      },
      "outputs": [],
      "source": [
        "unique_classes = new_ds['Label'].unique()\n",
        "print(\"Unique classes:\", unique_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm6_YFGUUg4k"
      },
      "outputs": [],
      "source": [
        "new_ds[[\"Label\"]] = new_ds[[\"Label\"]].apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar3VJxXNc4rh"
      },
      "outputs": [],
      "source": [
        "new_ds\n",
        "'''name = \"new_ds.csv\"\n",
        "new_ds.to_csv(name, index=False)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkCPItnoc_qg"
      },
      "outputs": [],
      "source": [
        "X = new_ds['Text']\n",
        "y = new_ds['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miqvh5ckmZ45"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_7o2QYtdFVm"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6GkjEp2bCMr"
      },
      "outputs": [],
      "source": [
        "def augment_text(text, num_aug=3):\n",
        "    augmented_texts = []\n",
        "    aug = naw.SynonymAug()\n",
        "    for _ in range(num_aug):\n",
        "        augmented_text = aug.augment(text)\n",
        "        augmented_texts.append(augmented_text)\n",
        "    return augmented_texts\n",
        "\n",
        "X_train_augmented = []\n",
        "y_train_augmented = []\n",
        "X_test_augmented = []\n",
        "y_test_augmented = []\n",
        "\n",
        "\n",
        "\n",
        "for text, label in zip(X_train, y_train):\n",
        "    if label == 1:\n",
        "        augmented_texts = augment_text(text)\n",
        "        X_train_augmented.extend(augmented_texts)\n",
        "        y_train_augmented.extend([label] * len(augmented_texts))\n",
        "for text, label in zip(X_test, y_test):\n",
        "    if label == 1:\n",
        "        augmented_texts = augment_text(text)\n",
        "        X_test_augmented.extend(augmented_texts)\n",
        "        y_test_augmented.extend([label] * len(augmented_texts))\n",
        "\n",
        "X_train_resampled = np.concatenate((X_train.values.reshape(-1, 1), np.array(X_train_augmented).reshape(-1, 1)))\n",
        "y_train_resampled = np.concatenate((y_train, y_train_augmented))\n",
        "\n",
        "X_test_resampled = np.concatenate((X_test.values.reshape(-1, 1), np.array(X_test_augmented).reshape(-1, 1)))\n",
        "y_test_resampled = np.concatenate((y_test, y_test_augmented))\n",
        "\n",
        "X_train_resampled = pd.Series(X_train_resampled.squeeze())\n",
        "y_train_resampled = pd.Series(y_train_resampled.squeeze())\n",
        "\n",
        "X_test_resampled = pd.Series(X_test_resampled.squeeze())\n",
        "y_test_resampled = pd.Series(y_test_resampled.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLh-CSdZ98ZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_resampled, dtype=tf.string)\n",
        "y_train_tensor = tf.convert_to_tensor(tf.keras.utils.to_categorical(y_train_resampled, num_classes=13), dtype=tf.float32)\n",
        "\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_resampled, dtype=tf.string)\n",
        "y_test_tensor = tf.convert_to_tensor(tf.keras.utils.to_categorical(y_test_resampled, num_classes=13), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n97kwVsbdMfE"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_zR1xrp38Je"
      },
      "outputs": [],
      "source": [
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "outputs['pooled_output']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_bert_embed = bert_preprocess(X_train_resampled)\n",
        "X_train_bert_embed = bert_encoder(X_train_bert_embed)[\"pooled_output\"]\n",
        "\n",
        "X_test_bert_embed = bert_preprocess(X_test_resampled)\n",
        "X_test_bert_embed = bert_encoder(X_test_bert_embed)[\"pooled_output\"]"
      ],
      "metadata": {
        "id": "9v_3gschfUAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2_WwXTz4HLI"
      },
      "outputs": [],
      "source": [
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "\n",
        "'''l = tf.keras.layers.Dense(128, activation='gelu', name=\"hidden\")(l)\n",
        "l = tf.keras.layers.Dropout(0.5, name=\"dropout_2\")(l)\n",
        "\n",
        "l = tf.keras.layers.Dense(64, activation='gelu', name=\"hidden_2\")(l)\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout_3\")(l)\n",
        "\n",
        "l = tf.keras.layers.Dense(32, activation='gelu', name=\"hidden_3\")(l)\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout_4\")(l)\n",
        "\n",
        "l = tf.keras.layers.Dense(16, activation='gelu', name=\"hidden_4\")(l)\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout_5\")(l)'''\n",
        "\n",
        "output_layer = tf.keras.layers.Dense(13, activation='softmax', name=\"output\")(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MciiM7re4Nvr"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[text_input], outputs = [output_layer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5kldC1X4R8L"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWbt-sll4Ur_"
      },
      "outputs": [],
      "source": [
        "METRICS = [tf.keras.metrics.F1Score(\n",
        "    average=None, threshold=None, name='f1_score', dtype=None\n",
        "),\n",
        "    tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "optimizer1 = tf.keras.optimizers.Adafactor(\n",
        "    learning_rate=0.001,\n",
        "    beta_2_decay=-0.8,\n",
        "    epsilon_1=1e-30,\n",
        "    epsilon_2=0.001,\n",
        "    clip_threshold=1.0,\n",
        "    relative_step=True,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adafactor')\n",
        "optimizer2=tf.keras.optimizers.AdamW(\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=0.004,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='AdamW')\n",
        "optimizer3 = tf.keras.optimizers.Lion(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.99,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Lion')\n",
        "optimizer4=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adam')\n",
        "\n",
        "optimizer5=tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"SGD\")\n",
        "\n",
        "optimizer6=tf.keras.optimizers.Adadelta(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.95,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"Adadelta\")\n",
        "\n",
        "optimizer7=tf.keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name=\"Adagrad\")\n",
        "\n",
        "optimizer8=tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=100,\n",
        "    jit_compile=True,\n",
        "    name=\"RMSprop\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwhpi04F4v4C"
      },
      "outputs": [],
      "source": [
        "base_models = []\n",
        "\n",
        "model_1 = tf.keras.models.clone_model(model)\n",
        "model_1.compile(optimizer=optimizer1, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_1)\n",
        "\n",
        "model_2 = tf.keras.models.clone_model(model)\n",
        "model_2.compile(optimizer=optimizer2, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_2)\n",
        "\n",
        "model_3 = tf.keras.models.clone_model(model)\n",
        "model_3.compile(optimizer=optimizer3, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_3)\n",
        "\n",
        "model_4 = tf.keras.models.clone_model(model)\n",
        "model_4.compile(optimizer=optimizer4, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_4)\n",
        "\n",
        "model_5 = tf.keras.models.clone_model(model)\n",
        "model_5.compile(optimizer=optimizer5, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_5)\n",
        "\n",
        "model_6 = tf.keras.models.clone_model(model)\n",
        "model_6.compile(optimizer=optimizer6, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_6)\n",
        "\n",
        "model_7 = tf.keras.models.clone_model(model)\n",
        "model_7.compile(optimizer=optimizer7, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_7)\n",
        "\n",
        "model_8 = tf.keras.models.clone_model(model)\n",
        "model_8.compile(optimizer=optimizer8, loss='categorical_crossentropy', metrics=METRICS)\n",
        "base_models.append(model_8)\n",
        "\n",
        "train_predictions = []\n",
        "for model in base_models:\n",
        "    train_pred = model.predict(X_train_tensor)\n",
        "    train_predictions.append(train_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_train_predictions = np.hstack(train_predictions)\n",
        "X_train_combined = np.hstack((X_train_bert_embed, stacked_train_predictions))\n",
        "\n"
      ],
      "metadata": {
        "id": "casT750TFa1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = []\n",
        "for model in base_models:\n",
        "    test_pred = model.predict(X_test_tensor)\n",
        "    test_predictions.append(test_pred)\n",
        "\n",
        "stacked_test_predictions = np.hstack(test_predictions)\n",
        "X_test_combined = np.hstack((X_test_bert_embed, stacked_test_predictions))"
      ],
      "metadata": {
        "id": "aj5j9ifGhyg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}"
      ],
      "metadata": {
        "id": "Gq4RnRC_XGVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_classifier = GradientBoostingClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "7LrrIgwLXH8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(gb_classifier, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "grid_search.fit(X_train_combined, np.array(y_train_resampled))\n",
        "\n",
        "best_n_estimators = grid_search.best_params_['n_estimators']\n",
        "best_learning_rate = grid_search.best_params_['learning_rate']"
      ],
      "metadata": {
        "id": "aMkDoR0_e5hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best n_estimators:\", best_n_estimators)\n",
        "print(\"Best learning_rate:\", best_learning_rate)"
      ],
      "metadata": {
        "id": "BAhWmpt_XUc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_classifier = GradientBoostingClassifier(n_estimators=best_n_estimators,\n",
        "                                           learning_rate=best_learning_rate,\n",
        "                                           random_state=42)\n",
        "model = gb_classifier.fit(X_train_combined, y_train_resampled)\n",
        "\n"
      ],
      "metadata": {
        "id": "bd48DqRbWPPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = model.predict(X_test_combined)\n",
        "predicted_class_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "siofyvC2FieO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_class_labels[0:20])"
      ],
      "metadata": {
        "id": "2HvI8fW9ijEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "test_predictions = gb_classifier.predict(X_test_combined)\n",
        "predicted_class_labels = label_encoder.inverse_transform(test_predictions)\n",
        "true_class_labels = label_encoder.inverse_transform(y_test_resampled)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_class_labels, predicted_class_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(true_class_labels, predicted_class_labels)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "kpb044EJGTzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_class_labels, predicted_class_labels)\n",
        "precision = precision_score(true_class_labels, predicted_class_labels, average='macro')\n",
        "recall = recall_score(true_class_labels, predicted_class_labels, average='macro')\n",
        "f1 = f1_score(true_class_labels, predicted_class_labels, average='macro')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "sic4UQ4P00UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gnH4m4U4zuD"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDmRwUIkM5r_"
      },
      "outputs": [],
      "source": [
        "model.save(\"NLP_TEXT_CLASSIFICATION_saved_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcuvgMKXeqk8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCVxS_d7WaP6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6n_RFK4dao6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6jdnLxXdcx_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smyUOjFWoPLY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHKPARkhuXnz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk7y0osvy5Wm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDfiaUyzz6Gx"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"LLP_saved_model\")\n",
        "def check(line):\n",
        "    prediction = model.predict(line)\n",
        "    predicted_labels = np.argmax(prediction, axis=1)\n",
        "    predicted_class_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "    dic = {0: 'ANALYSIS', 1: 'ARG_PETITIONER', 2: 'ARG_RESPONDENT', 3: 'FAC', 4: 'ISSUE', 5: 'NONE', 6: 'PREAMBLE', 7: 'PRE_NOT_RELIED', 8: 'PRE_RELIED', 9: 'RATIO', 10: 'RLC', 11: 'RPC', 12: 'STA'}\n",
        "\n",
        "    for label in predicted_class_labels:\n",
        "        if label in dic:\n",
        "            print(dic[label])\n",
        "#Put your statement here:\n",
        "line = ['3. The court below answered the above points in the affirmative and accordingly had convicted the accused to undergo simple imprisonment for three years and pay a fine of Rs.5,000/- for the offence punishable under section 498-A IPC and 10 years simple imprisonment and to pay fine of Rs.10,000/- for the offence punishable under Section 306 of the IPC.']\n",
        "check(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_sUgRLg1nRk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7MXPbYTI204"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}